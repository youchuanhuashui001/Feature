# 嵌入式C语言自我修养：从芯片、编译器到操作系统

## 1. 计算机体系结构与CPU工作原理

### 1.1 图灵机

​		图灵机的构造能够看作是一条无限长的指代Tape、一个读写头Head、一套控制规则Table、一个状态寄存器。

​		工作方式：读写头可以一直读取纸带，图灵机根据自己有限的控制规则，根据纸带的输入，不断更新机器的状态，并将输出打印到纸带上。

![image-20220522174928820](image/image-20220522174928820.png)

​		对比：

|      图灵机       |          现代计算机          |
| :---------------: | :--------------------------: |
|   无限长的纸带    |        相当于程序代码        |
|  一个读写头Head   |      相当于程序计数器PC      |
| 一套控制规则Table |    相当于CPU有限的指令集     |
|  一个状态寄存器   | 相当于程序或计算机的状态输出 |

### 1.2 CPU内部结构及工作原理

​		CPU内部构造很简单，只包括基本的算数逻辑运算单元、控制单元、寄存器等，仅支持有限个指令。程序代码存储在内存中，CPU可以从内存中一条一条地取指令、翻译指令并执行它。

![image-20220522175341769](image/image-20220522175341769.png)

​		ALU：只是纯粹的运算单元，要想完成一个指令运行的整个流程，还需要控制单元的协助。

​		控制单元：根据程序寄存器PC中的地址，不断从内存RAM中取指令，放到指令寄存器中并进行译码，将指令中的操作码和操作数分别送到ALU，执行相应的运算。



​		目前的CPU设计，一般都使用VHDL或Verilog硬件描述语言来整合ALU、控制单元、寄存器、Cache等电路模块，然后通过EDA工具将其转换为逻辑门电路。



### 1.3 CPU设计流程

​		集成电路设计一般分为模拟IC设计、数字IC设计和数模混合IC设计。数字IC设计一般是通过HDL编程和EDA工具来实现一个特定逻辑功能的数字集成电路的。

​		以设计一款ARM架构的SoC为例，基本设计流程如下：

![image-20220522182006064](image/image-20220522182006064.png)

1. 设计芯片规格

   根据需求，设计出芯片基本的框架、功能，进行模块划分。有些复杂的芯片可能还需要建模，使用MATLAB、CADENCE等工具进行前期模拟和仿真。

2. HDL代码实现
   使用VHDL或Verilog硬件描述语言把要实现的硬件功能描述出来，接着通过EDA工具不断仿真、修改和验证，直到芯片的逻辑功能完全正确。这种仿真一般称为前端仿真(简称前仿)，前仿只验证芯片的逻辑功能是否正确，不考虑延时等因素。例如设计一个1位加法器，通过EDA工具编写Verilog代码实现：

   ```verilog
   module adder(
   	input x,y,
       output carry,out
   );
       assign {out,carry} = x + y;
   endmodule
   ```

   

3. 逻辑综合
   前仿通过以后，通过EDA工具就可以将HDL代码转换成具体的逻辑门电路。专业说法是将HDL代码翻译成门级网表。

   ![image-20220522182537361](image/image-20220522182537361.png)

4. 仿真验证

   通过逻辑综合生成的门级电路，已经包含了延时等各种信息，接下来需要对这么门级电路进行进一步的静态时序分析和验证。为了提高工作效率，除了使用仿真软件，有时候也会借助FPGA平台进行验证。

   前端仿真发生在逻辑综合之前，专注于验证电路的逻辑功能是否正确；逻辑综合后的仿真，一般称为后端仿真，简称后仿。后端仿真会考虑延时等因素。  

5. 后端设计

   通过前端设计，已经生成了门级网表电路，但门级网表电路和实际的芯片电路之间还有一段距离，需要对其进行完善，进一步设计成物理版图，也就是芯片代工厂做掩模版需要的电路板图。

   物理版图验证通过后，芯片设计公司就可以将这个物理版图以GDSII文件的格式交给芯片制造代工厂去流片。到此，整个芯片设计、仿真、验证的流程就结束了，即tap-out。



### 1.4 计算机体系结构

​	CPU内部的结构其实很简单，除了ALU、控制单元、寄存器和少量Cache，需要额外的存储器来存放编写好的程序。

​	存储器按照存储类型可分为易失性存储器和非易失性存储器。易失性存储器如SRAM、DDR SDRAM等，一般用作计算机的内部	存储器，所以又被称为内存。这类存储器支持随机访问，<font color=Red>CPU可以随机到它的任意地址去读写数据</font>font>，访问非常方便，但缺点	是断电后数据会立即消失，无法永久保存。非易失性存储器一般用作计算机的外部存储器，也被称为外存，如磁盘、Flash等，	这类存储器支持数据的永久保存，<font color=red>断电后数据不会丢失，但缺点是不支持随机访问，访问速度也不如内存。</font>

​	为了兼顾存储和效率，计算机系统一般会采用内存+外村的存储结构：程序指令保存在磁盘、NAND Flash、SD卡等外部存储	器中，当程序运行时，相应的程序会首先加载到内存，然后CPU从内存一条一条地取指令、翻译指令和运行指令。

​	计算机主要用来处理数据，编写的程序，除了指令，还有各种各样的数据，指令和数据都需要保存在存储器中，根据保存方式的不同，计算机可分为两种不同的架构：冯·诺依曼架构<font color=red>(程序中的指令和数据混合存储，存储在同一块存储器上)</font>和哈弗架构<font color=red>(程序中的指令和数据被分开独立存储，分别被存放到程序寄存器和数据寄存器，每个存储器都独立编址，独立访问，而且指令和数据可以在一个时钟周期内并行访问)</font>。

​	由于CPU和内存之间工作频率差距大，CPU引入了Cache机制：指令Cache和数据Cache，用来缓存数据和指令，提升计算机的运行效率。

​	现代的ARM SoC芯片架构一般如下，SoC芯片内部的Cache层采用哈弗架构，集成了指令Cache和数据Cache。当CPU到RAM中读数据时，内存RAM不是一次只传输要读取的指定字节，而是一次缓存一批数据到Cache中，等下次CPU再去取指令和数据时，可以先到这两个Cache中看看要读取的数据是不是已经缓存到这里了，如果没有缓存命中，再到内存中读取。当CPU写数据到内存RAM时，也可以先把数据暂时写到Cache里，然后等待时机将Cache中的数据刷新到内存中。Cache缓存机制大大提高了CPU的访问效率，而SoC芯片外部则采用冯·诺依曼架构，工程实现简单。  

![image-20220522201712492](image/image-20220522201712492.png)



## 2. 程序的编译、链接、安装和运行



​		嵌入式开发和桌面开发不太一样：处理器平台和软件生态碎片化、多样化。为了提高性价比，不同的嵌入式系统往往采取更灵活的配置：不同的CPU平台、不同大小的存储、不同的启动方式，导致在编译程序时，有时候不仅要考虑一个嵌入式的平台、存储器的地址空间，还要考虑将我们的程序代码"烧"到什么地方、加载到内存什么地方、如何执行。



### 2.1 编译过程

​		在一个多文件的C项目中，编译器是以C源文件为单位进行编译的。在编译的不同阶段，编译程序会调用不同的工具来完成不同阶段的任务。包括：预处理器、编译器、汇编器、链接器。

​		预处理过程：在编译源程序之前，先处理源文件中的各种与处理命令。将头文件展开、宏展开、条件编译、删除注释、添加行号和文件名标识等。

​		编译过程：编译器调用一系列解析工具，去分析这些C代码，将C源文件编译成汇编文件。主要进行词法分析、语法分析、语义分析、中间代码生成、汇编代码生成、目标代码生成。

​		汇编过程：使用汇编器将前一阶段生成的汇编文件翻译成目标文件。通过编译生成的可重定位目标文件，都是以零地址为链接起始地址进行链接的。也就是说，编译器在将源文件翻译成可重定位目标的过程中，将不同的函数编译成二进制指令后，是从零地址开始一次将没一个函数的指令序列存放到代码段中，每个函数的入口地址也就从零地址开始依次往后偏移。

​		链接过程：链接器将各个目标文件组装在一起后，通过重新修改各个目标文件中的变量或函数的地址，成为重定位。并且将需要重定位的符号收集起来，生成一个重定位表，以Section的形式保存到每个可重定位目标文件中。

​		符号表和重定位表：在整个编译过程中，符号表主要用来保存源程序中各种符号的信息，包括符号的地址、类型、占用空间的大小等。另一方面也复制编译器编译代码的生成，包括地址与空间的分配、符号决议、重定位等。



### 2.2 链接过程

​		在一个C项目的编译中，编译器以C源文件为单位，将一个个C文件翻译成对应的目标文件。生成的每一个目标文件都是由代码段、数据段、BSS段、符号表等Section组成。这些Section从目标文件的零地址偏移地址开始按照顺序一次排放，每个段中的符号相当于零地址的偏移，其实就是每个符号的地址，这样程序中定义的变量、函数名等，都有了一个暂时的地址。

​		链接过程的第一步，就是将各个目标文件分段组装。连接器将编译器生成的各个可重定位目标文件重新分解组装：将各个目标文件的代码段放在一起，作为最终生成的可执行文件的代码段；将各个目标文件的数据段放在一起，作为可执行文件的数据段。其它Section也会按照同样的方法进行组装，最终生成以下的可执行文件的雏形。

![image-20220531193653651](image/image-20220531193653651.png)

​		链接器会在可执行文件中创建一个全局的符号表，收集各个目标文件符号表中的符号，然后将其统一放到全局符号表中。通过这个步骤，一个可执行文件中的所有符号都有了自己的地址，并保存在全局符号表中，但此时全局符号表还都是原来在各个目标文件中的地址，即相对于零地址的偏移。

​		程序在链接程序时需要制定一个链接起始地址，链接起始地址一般也就是程序要加载到内存中的地址。通过使用链接脚本来规定各个段的组装顺序、起始地址、位置对齐等信息，同时对输出的可执行文件、运行平台、入口地址等信息做了详细的描述。链接器就是根据链接脚本定义的规则来组装可执行文件的，并最终将这些信息以Section的形式保存到可执行文件的ELF Header中。

​		假设在一个嵌入式系统中，内存RAM的起始地址是0x60000000，在链接脚本中指定内存中的一个合法地址作为链接起始地址。程序运行时，加载器首先会解析可执行文件中的ELF Header头部信息，验证程序的运行平台和加载地址信息，然后将可执行文件加载到内存中对应的地址，程序就可以正常运行。



### 2.3 重定位

​		符号表中的每个符号值，也就是每个函数、全局变量的地址，还是原来各个目标文件中的值，还都是基于零地址的偏移。链接器将各个目标文件重新分解组装后，各个段的起始地址都发生了变化。

​		在可执行文件中，各个段的起始地址都发生了变化，那么各个段中的符号地址也要跟着发生变化。如图中的main()函数和sub()函 数，它们在原来各自的目标文件中，相对于零地址的偏移分别是0x10和0x30，main.o文件中代码段的大小为len，经过链接器分解后，所有 目标文件的代码段组装在一起，原来目标文件的各个代码段的起始地 址也发生了变化：此时main()函数和sub()函数相对于a.out文件头的 地址也就变成了0x10和len+0x30。链接器在链接程序时一般会基于某 个链接地址link_addr进行链接，所以最后main()函数和sub()函数的真实地址就变成了link_addr+0x10、link_addr+len+0x30。

![image-20220531195430645](image/image-20220531195430645.png)

### 2.4 程序的运行

​		程序的运行分两种情况：一种是在有操作系统的环境下执行一个应用程序，另一种是在无操作系统的环境下执行一个裸机程序。在不同的环境下执行程序，文件的格式一般也会不一样。如Linux下是elf格式，逻辑一般是bin/hex格式。原理都是：将指令加载到内存中的指定位置，而这个指定位置往往又与可执行文件链接时的链接地址有关。

​		一个装有操作系统的计算机系统，当执行一个app时，首先会运行一个叫做加载器的程序。加载器会根据软件的安装路径信息，将可执行文件从ROM加载到内存，然后进行一些初始化、动态库重定位相关的操作，最后才跳转到程序的入口运行。

​		Linux环境下运行的程序一般都会被封装成进程，参与操作系统的统一调度和运行。在Shell环境下运行一个程序，Shell中断程序一般会先fork一个子进程，创建一个独立的虚拟进程地址空间，接着调用execve函数将要运行的程序加载到进程空间：通过可执行文件的文件头，找到程序的入口地址，建立进程虚拟地址空间与可执行文件的映射关系，将PC指针设置为可执行文件的入口地址，即可启动运行。

![image-20220531201639288](image/image-20220531201639288.png)

​	程序链接时的链接地址其实都是虚拟地 址。程序运行时，虽然每个进程的地址空间都是一样 的，但是每个进程都有自己的页表，页表里的每一个条目叫页表项， 页表项里存储的是虚拟地址和物理地址之间的映射关系，相同的虚拟 地址经过MMU硬件转换后，会分别映射到物理内存的不同区域，彼此相互隔离和独立，一点也不会起冲突

![image-20220531201812440](image/image-20220531201812440.png)



### 2.5 BSS段

​		对于未初始化的全局变量和静态局部变量，编译器将其放置在BSS段中，BSS段是不占用可执行文件存储空间的，设置BSS段的目的主要就是减少可执行文件的体积。

​		虽然BSS段在可执行文件中不占用存储空间，但是当程序加载到内存运行时，加载器会在内存中给BSS段开辟一段存储空间。

![image-20220531202731438](image/image-20220531202731438.png)



### 2.6 链接静态库

​		库分为静态库和动态库两种。如果我们在项目中引入了库函数，则在编译时，链接器会将我们引用的函数代码或变量，链接到可执行文件里，和可执行程序组装在一起，这种库被称为静态库，即在编译阶段链接的库。

​	

### 2.7 动态链接

​		静态链接的缺点：生成的可执行文件体积较大，当多个程序引用相同的公共代码时，这些公共代码会多次加载到内存，浪费内存资源。

​		动态链接库：在程序运行时才参与链接的库。节省了内存空间。一个软件采用动态链接，版本升级时主程序的业务逻辑或框架不需要改变，只需要更新对应的.dll或.so文件皆可。

​		动态库在编译阶段不参与链接，不会和可执行文件组装在一起，而是在程序运行时才被加载到内存参与链接，因此又叫做动态链接库。

​		动态链接需要考虑的一个重要问题就是加载地址。一个静态链接的可执行文件在运行时，一般加载地址等于链接地址，而且这个地址是固定的。可执行文件是操作系统帮我们创建一个子进程后，第一个被加载到进程空间的文件，此时进程的地址空间还是空的，所以不用考虑地址空间资源问题。动态链接库加载到内存中的地址则是随机的，因为每一个可执行文件的大小不同，加载到内存后剩余的地址空间也不尽相同，动态链接库的地址要根据进程地址空间的实际空闲情况随机分配。

​		在装载时重定位，动态链接库被加载到内存后，目标文件的起始地址也发生了变化，需要重定位。一个可执行文件对动态链接库的符号引用，要等动态链接库加载到内存后地址才能确定，然后对可执行文件中的这些符号修改皆可。---- 此时对于每个进程，动态库被加载到了内存的不同地址，也只能被进程自身共享，无法在多个进程间共享，无法节省内存。需要将动态库设计成放在任何地方，都可以执行，且能够被多个进程共享。

​		使用位置无关码：在模块内部，对函数和全局变量的引用要避免使用绝对地址，一般使用相对跳转代替。通过这种相对寻址的符号引用，可以做到代码与地址无关，把这段代码放在内存中的任何位置，都无需重定位，直接运行即可。



## 10.存储器

### 10.1. 存储器与接口

​		常见的存储器类型有ROM、FLASH、SDRAM、DRAM等，按存储模式主要分为ROM和RAM，ROM用来存储程序和数据，当程序运行时，这些程序和数据会从ROM加载到RAM，RAM支持随机读写，CPU可以直接从RAM中取指运行。



- Nor Flash：数据线、地址线分开，具有随机寻址功能

- Nand Flash：数据线、地址线复用，不支持随机寻址，要按页读取

- eMMC：将Nand Flash和读写控制器封装在一起，使用BGA封装。对外引出MMC接口，用户可以通过MMC协议读写Nand Flash

- SD：将Nand Flash和读写控制器封装在一起，使用SIP封装，对外引出SDIO接口，用户可以使用SDIO协议进行读写，简化了Nand Flash的读写方式

- RAM：随机寻址存储器(Random Access Memory)，可读可写，断电数据丢失。RAM按照硬件电路的实现方式可分为SRAM和DRAM。
  - DRAM：动态随机存取存储器(Dynamic Random Access Memory)，每1bit的数据存储使用一个晶体管和一个电容实现。DRAM读写速度相比SRAM会慢很多。而且DRAM读写还需要控制器的支持。
  - SDRAM：同步动态随机存取内存(Synchronous DRAM)对DRAM做了改进，省去了电容充电时间，并改用流水线操作，将DRAM的读写速度提高



### 10.2. 存储映射

​		ARM处理器上电复位后，PC寄存器为0，CPU默认是从零地址去读取指令执行的，通过存储映射，将不同的存储器映射到零地址，那么CPU复位后，就可以到不同的存储器取指令运行，从而实现多种启动方式。

​		X86架构的处理器一般对外设独立编址，为它们分配独立的地址空间，该地址和内存地址没有任何关系，CPU不能像读写内存那样直接对这些端口进行读写，要通过专门的IN/OUT命令去读写这些端口来配置相关的寄存器

​		ARM架构的处理器一般会将外设的寄存器、缓冲器、FIFO和内存统一编址，外设的寄存器和内存一起共享地址空间，CPU可以按照内存读写的方式，直接读写这些寄存器来管理和操作外设。



### 10.3.MMU

#### 10.3.1. 地址转换

​		MMU主要用来将虚拟地址转换为物理地址，每个App编译时都以虚拟地址为链接地址，甚至使用相同的链接地址都可以，当多个App运行时，CPU会通过MMU将相同的虚拟地址映射到不同的物理地址，每个App都有各自的物理内存空间，互不影响各自的运行。

​		eg：

​		有两个应用程序app1.c和app2.c，编写好程序以后，通过ARM交叉编译器编译生成两个可执行文件，然后在同一个ARM平台上运行，ARM平台的内存起始物理地址为0x30000000，使用readelf查看两个app的入口地址，发现两个app的链接地址是相同的，而且都是虚拟地址。

​		MMU会根据每个进程的地址转换表将相同的虚拟地址转换为不同的物理地址。当PC指针执行app1时，到0x1000虚拟地址处取指令，经过MMU地址转换后得到实际物理内存的0x30001000处取指令。当PC指针执行app2时，同样会到0x1000虚拟地址处取指令，经过MMU地址转换后实际物理内存的0x30005000处取指令。

​		对于每个应用程序来说，都拥有独立的内存空间，但是共用相同的物理地址。每个虚拟地址通过地址转换表都可以与实际的物理内存地址一一对应，不同的app有不同的地址转换表，相同的虚拟地址会映射到不同的物理地址上。|
![image-20220524193542490](image/image-20220524193542490.png)

​		这种用法太浪费空间，采用以4KB为单位将内存划分为页，并以页为单位进行映射，地址转换表只保存每个页的虚拟起始地址到物理起始地址的转换关系。并通过页表来保存页的转换信息。
![image-20220524194443871](image/image-20220524194443871.png)



#### 10.3.2. 权限管理

​		MMU和页表可以针对不同的内存区域设置不同的权限，防止内存被践踏，从而保障系统的安全运行。

​		Linux系统中内存管理子系统已经把整个4GB的内存空间划分为用户空间和内存空间，操作系统代码运行在内核空间，普通app运行在用户空间。app无法访问内核空间，如果要访问，则要通过中断或系统调用接口统一管理。

​		一个页表有若干个页表项构成，每个页表项不仅包含地址转换信息，还<font color=red>包含每一个进程中不同内存区域的访问权限信息。</font>通过这种设计，可以对不同app映射到实际物理内存的地址空间进行权限管理。



### 10.4 进程

​		在Linux环境下运行一个app，操作系统会把这个程序包装成进程的形式，每一个进程都使用`task_struct`结构体来描述，所有的结构体链成一个链表，参与操作系统的统一调度和运行。每一个Linux进程都有其单独的4GB虚拟地址空间，并使用MMU来映射到不同的物理内存。

​		因为每个进程在物理内存上都是相互隔离的，无论一个函数是否可重入，无论这个函数是否线程安全，都可以在进程中调用。	
![image-20220524195344596](image/image-20220524195344596.png)

​		当不同进程之间需要相互通信时，应借助其它方法来进行通信(IPC)



### 10.5 线程

​		进程开销大，线程的切换速度快，多个线程共享线程中的代码段、数据段、地址空间、打开文件、信号处理程序等资源。每个线程都有自己单独的资源，如PC、寄存器上下文以及各自的栈空间。

​		因为多个线程共享进程资源，故当不同线程对共享资源访问时，要设计共享资源的安全访问和线程间同步问题，使用互斥锁、条件所和读写锁等来实现不同线程对共享资源的安全访问。



### 10.6 线程池

​		为了减少线程不断创建和销毁带来的开销，可以实现一个线程池，预先在线程池中创建一些线程，没有工作任务时，线程阻塞在池中，有任务时，则通过管理线程将任务分配到指定的线程执行。



# 函数调用

一个函数在执行过程中，如果需要调用其它函数，则一般会执行下面的过程：

1. 保存当前函数现场
2. 跳到调用函数执行
3. 恢复当前函数现场
4. 继续执行当前函数

如有一个ARM程序，在main()函数中对一些数据进行处理，运算结果暂存在R0寄存器中，接着调用另一个func()函数，调用结束后，返回main()函数继续处理数据。如果我们在func()函数中要使用R0用于保存函数的返回值，就会改变R0寄存器中的值，那么就篡改了main()函数中的暂存运算结果。当我们返回main()函数继续进行数据处理时，最后的结果肯定不正确。

解决方法：在跳到func()函数执行之前，先把R0寄存器的值保存到堆栈中，func()函数执行结束后，再将堆栈中的值恢复到R0寄存器，这样main()函数就可以继续执行了。

- 每一层函数调用，都会将当前函数的下一条指令地址，即返回地址压入堆栈保存，各级函数调用就构成了一个函数调用链。
- 在函数调用过程中，还有一个栈帧的概念。函数每调用一次，都会将当前函数的现场(返回地址、寄存器、临时变量等)保存在栈中，每一层函数调用都会将各自的现场信息保存在各自的栈中。这个栈就是当前函数的栈帧，每一个栈帧都有第十地址和结束地址，多层函数调用就会有多个栈帧，每一个栈帧都会保存上一层栈帧的起始地址，这样各个栈帧就形成了以一个调用链。
  - 在ARM处理器平台下，一般使用FP和SP这两个寄存器，分别指向当前函数栈帧的起始地址和结束地址。当函数继续调用其它函数，或运行结束返回上一级函数时，这两个寄存器的值也会发生变化，总是指向当前函数栈帧的起始地址和结束地址。

# 内联函数

- 建议编译器将指定的函数体插入并取代每一处调用该函数的地方，从而节省了每次调用函数带来的额外时间开销
- 编译器在编译过程中遇到内联函数，像宏一样，将内联函数直接在函数调用处展开，这样做就减少了函数调用的开销：直接执行内联函数展开的代码，不用再保存现场和恢复现场。
- 内联函数为什么定义在头文件中？
  - 因为它是一个内联函数，可以像宏一样使用，任何想使用这个内联函数的源文件，都不必亲自再去定义一遍，直接包含这个头文件，即可像宏一样使用。
- 为什么inline 函数经常使用static修饰呢？
  - 因为我们使用inline定义的内联函数，编译器不一定会内联展开，那么当一个工程中多个文件都包含这个内联函数的定义时，编译就有可能报重定义错误。而使用static关键字修饰，则可以将这个函数的作用于限制在各自的文件内，避免重定义错误的发生。

# 内建函数

- 内建函数，就是编译器内部实现的函数。这些函数和关键字一样，可以直接调用，无需像标准库函数那样，要先声明后使用。
- 内建函数的函数命名：通常以__builtin开头。这些函数主要在 编译器内部使用，主要是为编译器服务的。内建函数的主要用途如下：
  - 用来处理变长参数列表
  - 用来处理程序运行异常、编译优化、性能优化
  - 查看函数运行时的底层信息、堆栈信息等
  - 实现c标准库的常用函数

## 常用的内建函数

- 常用的内建函数主要有两个：__builtin_return_address() 和 __builtin_frame_address()

  - ```
    __buildin_return_address(LEVEL)
    ```

    - 这个函数用来返回当前函数或调用者的返回地址。
    - 函数的参数LEVEL表示函数调用链中不同层级的函数
      - 0：获得当前函数的返回地址
      - 1：获得上一级函数的返回地址
      - 2：获得上二级函数的返回地址

- linux内核中的likely和unlikely

  - 在Linux 内核中，我们使用__builtin_expect()内建函数，定义了两个宏

```C
#define likely(x) __built_in_excpect(!!(x),1)
#define unlikely(x) __built_in_excpect(!!(x),0)
    - 这两个宏的主要作用就是告诉编译器：某一分支发生的概率很高，或者很低，基本不可能发生。编译器根据这个提示信息，在编译程序时就会做一些分支预测上的优化。
```

- 可变参数宏
  - 可变参数宏的实现形式其实和变参函数差不多：用...表示变参列表，变参列表由不确定的参数组成，各个参数之间用逗号隔开。
  - 可变参数宏使用C99标准新增加的一个__VA_ARGS__预定义标识符来表示前面的参数列表，而不是用`va_list、va_start、va_end`去解析变参列表。
- linux 内核中的可变参数宏
  - 可变参数宏在内核中主要用于日志打印。

```C
#if define(CONFIG_DYNAMIC_DEBUG)
#define pr_dbug(fmt, ...) \
    dynamic_pr_debug(fmt, ##__VA_ARGS__)
#elif defined(DEBUG)
#define pr_debug(fmt, ...) \
    printk(KERN_DEBUG pr_fmt(fmt), ##__VA__ARGS__)
#else
#define pr_debug(fmt, ...) \
    no_printk(KERN_DEBUG pr_fmt(fmt), ##__VA__ARGS__)
```

# 宏连接符##

宏连接符##的主要作用就是链接两个字符串。

```C
#define A(x) a##x

int main(void)
{
  int A(1) = 2;// int a1 = 2;
  int A() = 3; // int a = 3;
  printf("%d, %d\n", a1, a);
  return 0;
}
```

## do_while 的妙用

- 在程序中很多时候能够看到在宏当中采用了 do{...}while(0)的形式，下面来查看这种结构的妙用：

```C
int main(void)
{
  if (1)
      printf("hello if\n");
  else
      printf("hello");
      printf("else\n");
      
  return 0;
}
```

# 大端和小端

- 在计算机中，位(bit)是最小的存储单位，在一个DDR SDRAM内存电路中，通常用一个电容器来表示：充电时高电位表示1，放点时低电位表示0.
- 8个bit 组成一个 byte，字节是计算机最基本的存储单位，也是最小的寻址单元，计算机通常以字节为单位进行寻址。
- 在一个32位的计算机系统中，通常4个字节组成一个字word。
- 一个数据在内存中有2中存储方式：高地址存储高字节数据，低地址存储低字节数据；或者高地址存储低字节数据，而低字节存储高字节数据。
- 将一个整型变量的值赋给一个字符型变量，通常会发生“截断”。

![img](https://secure2.wostatic.cn/static/eGzwY2i1CC6V4sbBrREjsd/image.png?auth_key=1675904117-5DX7aF5ik8F2xJzKcJHeHh-0-6a7f2740f68334e05b8d151920afbe49)

# 分段之后的内存

- 计算机内存RAM支持随机寻址功能，在C语言中对内存的访问可直接通过地址进行读写。内存一般可分为静态内存和动态内存，一个程序被加载到内存运行时，代码段和数据段就属于静态内存，而堆栈则 属于动态内存。静态内存的特点是内存中各个变量的地址在编译期间就确定了，在程序运行期间不再改变。而动态内存中变量的地址在程序运行期间是不固定的，如函数的局部变量，如果这个函数多次被调用运行，那么每次运行都要在栈上随机分配一个栈帧空间；如果每次分配的栈帧地址不同，那么这个函数内局部变量地址也会跟着动态变化，每次都不一样。
- 静态内存由于在整个程序运行期间不再变化，因此我们可以通过变量名直接访问，变量的地址在编译期间就已经确定了。对于栈，因为每次函数的运行地址不固定，所以只能通过栈帧指针结合相对寻址来访问。在函数调用过程中，虽然每次给函数分配的栈帧空间地址不同，但每个局部变量在函数栈帧内相对栈帧指针FP的相对偏移不会改变，因此每一次函数运行都可以正常访问。而对于用户使用malloc()函数申请的堆内存，不仅是动态变化的，而且还是匿名内存，我们无法借助变量名或栈指针来访问，只能使用指针来间接访问了。

# 指针和数组

![img](https://secure2.wostatic.cn/static/8qGAvJG2K4buUcdq1pW8Yg/image.png?auth_key=1675904117-vxA2n3DBh6nKrFTc6SGbDr-0-fd2cbf7df6bdd0aa766dafed4d2d672a)